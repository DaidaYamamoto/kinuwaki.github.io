<!DOCTYPE html>
<html>
  <head>
    <title>Metahuman 触ってみたメモ</title>
    <meta http-equiv="content-type" charset="utf-8">
    <meta keywords="Metahuman">
    <meta description="Digital Human Project">
  </head>
  <body>
  <h1>Metahuman 触ってみたメモ</h1>


  <h2>最初に</h2>
  <video src="./Metahuman作業.mp4" controls width="50%"></video><br>
　<a href="https://www.unrealengine.com/ja/digital-humans?sessionInvalidated=true">Metahuman</a>は簡単にリアルなデジタルヒューマンを作成できるツールです。一通り触ってみたけども、Photogrammetry を色々触って色々溜まっていたモヤモヤに対することに対する回答がすべて揃ってた印象です。今後 Procedual な Digital Human を進めようとする際に、同じようなアプローチを採用したほうが絶対にいいかなと思いました。<br>
　一番のミソはとにかく全部ベースメッシュを丁寧に作っているところです。<br>
　リグはベースメッシュに対してつけられています。ベースメッシュはパーツごとのグループ分けがしっかりされており、髪の毛が生える場所も丁寧に決められています。これにより髪モデラー、アニメーター、各パーツの担当が並列で作業することができるのが素晴らしいなあと思います。まあゲームでは普通にやってることなんですが、バリエーションが作られやすくなっておりいいなと思いました。Digital Human の研究をやるにしてもちゃんとこういうファンデーションを作ってその上で各自が研究をするのがいいんじゃないかなと思いました。

  <h2>顔</h2>
　このツールでやった！と一番思ったのはベースメッシュ一番大事ともいえる顔のブレンドを 50 程度ある顔のプリセットの組み合わせで表現しているところでした。そしてアジア系の顔はほぼ 0。やはり日本人のベース顔を集めて、集めて、集めて、集めることには意義がありそうな気がします。ベースのアルベドに乗っける肌テクスチャ(Normal + Roughness 相当かな？)はパラメーターで変化できます。乱数で作っている感じもしますし、Deep Learning で作ってるかもしれない感じでした。

  <h2>目</h2>
  <video src="./目.mp4" controls width="50%"></video><br>
　フォトグラメトリをやっていて一番最初に悩んだのは目のモデリングです。目は屈折率や Sclera テクスチャをはじめる色々なパラメーターがありますが、ゲームでもそれなりに使用されているため、それなりにパラメトリックモデルとしては確立しています。ですので、この目モデルを基にフォトグラメトリベースで Inverse Rendering をするのがいいのかなとも思いましたが、Metahuman を触っていて思ったのは目はそれほど見た目の印象に変化を与えないかもという印象でした。とりあえず 1 個死ぬ気でそれを作ればあとは同じ目をひたすら流用するのでもそんなに運用として問題はないきがしました。<br>
　<b>参考</b><br>
　<a href="https://docs.unrealengine.com/en-US/Resources/Showcases/DigitalHumans/index.html">Unreal Engine</a><br>
　<a href="http://www.iryoku.com/next-generation-life">NEXT GENERATION LIFE</a><br>
　<a href="https://studios.disneyresearch.com/2016/07/11/lightweight-eye-capture-using-a-parametric-model/">Lightweight Eye Capture Using a Parametric Model</a><br>

  <h2>アニメーション</h2>
  <video src="./アニメーション.mp4" controls width="50%"></video><br>
　Metahuman の素晴らしいところは、ベースメッシュに対してしっかりリグを作っているところです。そして専属アニメーターがそれなりのアニメーションを事前に用意しています。いわゆるゲーム業界でよくやられているブレンドシェイプの組み合わせでやりくりしてる感じではなく、手付けアニメーションのアプローチですが、それのお陰で今回のサンプルのアニメーションのクオリティは劇的に高いです。やっぱりフェイシャルキャプチャや、ブレンドシェイプでの表現の限界がここらへんなのかもしれませんね。といっても技術者にはどうしようもできないですけども<br>

  <h2>髪の毛</h2>
  <video src="./髪の毛.mp4" controls width="50%"></video><br>
　プロダクションでは髪の毛のモデリングは基本的に Maya で行います。フォトグラメトリには帽子をかぶっているので、ああ、いったいここからどうやって髪の毛の対応したらいいのだろうと悩んでいたら、MetaHuman では 27 個のプリセットを選ぶだけの形になっていました。ああ、これでいいんだと。つまり髪の毛の生える場所をあらかじめベースメッシュで決めておいて、それの組み合わせでやりくりしているんだと。髪の毛は 1 個テンプレが用意できさえすれば、それをとりあえず使えばいいという考えでこれで色々気持ち的に楽になりました。<br>

  <h2>まつ毛</h2>
  <video src="./まつ毛.mp4" controls width="50%"></video><br>
　まつ毛のモデリングは基本的には Maya で行います。これもどうやってやろうかなあと悩んでいたんですが、MetaHuman では 5 つのまつげのプリセットを選べるだけという割り切り仕様になっており、ああ、まつ毛はそれくらいの扱いでもいいのかと気が楽になりました。<br>

　<h2>クラウドレンダリング<h2>
　このツールを触っていて、お、と思った特徴の一つがこれがクラウドレンダリングで行われているところでした。ハイエンド GPU でしか動かないからなのか、単にユーザーの作業データを集めたいのか、それとも開発中の機能が盛りだくさんの Unreal Engine を使用しているので AWS で運営したほうがよかったのか、理由はわかりませんがアプローチとしては面白いなと思いました。Stadia とか GeForce GO のようなサービスを除いてはこのクオリティでサーバーレンダリングが行われてるソフトウェアははじめて触りました。

  <h4>email: ShinichiKinuwaki [at] gmail.com</h4>
  </body>
</html>